{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Android Object Detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "HP1lv8LsJ5xc"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXoBAgFStU0A",
        "colab_type": "text"
      },
      "source": [
        "Upgrade RAM in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMe66lm0tQUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upgrade ram\n",
        "a = []\n",
        "while(1):\n",
        "    a.append('1'*100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G75dMdyKB0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctCvQ_vJJHdO",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Tensorflow Object Detection API interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OajWLvpLfJZ",
        "colab_type": "text"
      },
      "source": [
        "Refs: \n",
        "- https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md\n",
        "- https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADfcEarjMlyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/PeppeDAlterio/android-object-detection.git /content/api\n",
        "\n",
        "!mv /content/api/generate_tfrecord.py /content/generate_tfrecord.py\n",
        "!mv /content/api/xml_to_csv.py /content/xml_to_csv.py\n",
        "!mv /content/api/data_augmentation.py /content/data_augmentation.py\n",
        "!mv /content/api/train_val_split.py /content/train_val_split.py\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim numpy==1.16\n",
        "\n",
        "%cd /content/api/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/api/research/:/content/api/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSFc6Z4XEhyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model to use (see MODELS_CONFIG)\n",
        "selected_model = 'ssd_mobilenet_v2_coco'\n",
        "\n",
        "# List of models (from Tensorflow Zoo-Garden)\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2_coco': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29', #http://download.tensorflow.org/models/object_detection/{NOME_MODELLO}.tar.gz\n",
        "        'pipeline_file': 'pipeline.config', # Dall'archivio ^\n",
        "        'batch_size': 32\n",
        "    }\n",
        "}\n",
        "\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7pK9x6DKH3e",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gIfN9FbOLZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/data\n",
        "!mkdir /content/data/images\n",
        "!mkdir /content/data/images/train\n",
        "!mkdir /content/data/images/val\n",
        "!mkdir /content/data/images/test\n",
        "!mkdir /content/data/annotations\n",
        "!mkdir /content/data/images/all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yro1DwVUvFvx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   Collect the images\n",
        "2.   Augment the data by running *data_augmentation.py* script\n",
        "3.   Label the dataset using a labelling tool such as labelImg (https://github.com/tzutalin/labelImg). Please be sure to use a proper XML format (e.g. Pascal VOC)\n",
        "4.   Move images and labels (xml) into */content/data/images/all/*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJsWp7ddt6UK",
        "colab_type": "text"
      },
      "source": [
        "## Split your dataset in training e validation set.\n",
        "You can also do this automatically by running the first code block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swjS8PSEt5wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train_val_split.py \\\n",
        "        --datadir='/content/data/images/all' \\\n",
        "        --split=0.1 \\\n",
        "        --train_output='/content/data/images/train' \\\n",
        "        --test_output='/content/data/images/val' \\\n",
        "        --image_ext='jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yua6gfbjRoIc",
        "colab_type": "text"
      },
      "source": [
        "Compute number of images in training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZs_Pr1p3d7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "num_train_images = 0\n",
        "num_val_images = 0\n",
        "\n",
        "for image in os.listdir('/content/data/images/train'):\n",
        "  if image.endswith('xml'):\n",
        "    num_train_images = num_train_images + 1\n",
        "\n",
        "for image in os.listdir('/content/data/images/val'):\n",
        "  if image.endswith('xml'):\n",
        "    num_val_images = num_val_images + 1\n",
        "\n",
        "print (\"Number of images in train set: \" + str(num_train_images) )\n",
        "print (\"Number of images in val set: \" + str(num_val_images) )\n",
        "\n",
        "steps_per_epoch = math.ceil(num_train_images/batch_size)\n",
        "print(\"Steps per epoch: \" + str(steps_per_epoch) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDdi6oHRuLO",
        "colab_type": "text"
      },
      "source": [
        "Generate TFRecord from both train and val set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZKtV8HOKLV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "# Path file da generare\n",
        "val_record_fname = '/content/data/annotations/val.record'\n",
        "train_record_fname = '/content/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/data/annotations/label_map.pbtxt'\n",
        "\n",
        "# Conversione coppie (jpg,xml) in un unico csv e generazione mappa dei label\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv \\\n",
        "                      --labelMapDir /content/data/annotations/\n",
        "!python xml_to_csv.py -i data/images/val -o data/annotations/val_labels.csv\n",
        "\n",
        "# Training set\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Validation set\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/val_labels.csv --output_path=data/annotations/val.record --img_path=data/images/val --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_d7yQaQWElL",
        "colab_type": "text"
      },
      "source": [
        "# Download and init model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDGbuzNGWOp4",
        "colab_type": "text"
      },
      "source": [
        "Ref: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfabY6yxWxPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IoU threshold from the original configuration of non-max suppression\n",
        "IOU_OLD_THRESHOLD = 0.6\n",
        "\n",
        "# New IoU threshold for non-max suppression\n",
        "IOU_THRESHOLD = 0.55\n",
        "\n",
        "# Number of steps\n",
        "num_steps = 10000 # steps_per_epoch*epochs # 200000\n",
        "\n",
        "# Number of evaluation steps. Comment to use the whole dataset\n",
        "# num_eval_steps = 50\n",
        "\n",
        "num_evals_samples = 100000\n",
        "\n",
        "%cd /content/api/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/api/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "\n",
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}\n",
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint\n",
        "\n",
        "import os\n",
        "\n",
        "!mkdir /content/tmp\n",
        "!cp {DEST_DIR}/{pipeline_file} /content/tmp/config.cfg\n",
        "pipeline_fname = '/content/tmp/config.cfg'\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # Set number of images in val set\n",
        "    s = re.sub('max_evals: [0-9]+',\n",
        "               'max_evals: {}'.format(num_evals_samples), s)\n",
        "    \n",
        "    ### Batch non-max suppression ###\n",
        "\n",
        "    # Set score threshold\n",
        "    s = re.sub('score_threshold: \".*?\"',\n",
        "               'score_threshold: {}'.format(\"1e-8\"), s)\n",
        "    \n",
        "    # Set IoU threshold\n",
        "    s = re.sub('iou_threshold: ' + str(IOU_OLD_THRESHOLD),\n",
        "               'iou_threshold: {}'.format(str(IOU_THRESHOLD)), s)\n",
        "    \n",
        "    # Rimozione batch_norm_trainable\n",
        "    s = re.sub('batch_norm_trainable: true', '', s)\n",
        "    s = re.sub('batch_norm_trainable: false', '', s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "!cat {pipeline_fname}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsCVuwvS2dM4",
        "colab_type": "text"
      },
      "source": [
        "# Estimating optimal learning rate\n",
        "If you do not know what's this about, skip this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz4d7aGr_yKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_from = -2.39794000662\n",
        "lr_to = -2.16\n",
        "print(\"From: \" + str(10**lr_from) )\n",
        "print(\"To: \" + str(10**lr_to) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scw_WVPy28z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "# Output model directory\n",
        "model_dir = '/content/fit_output'\n",
        "\n",
        "MAX_RANGE = 10\n",
        "\n",
        "for i in range(0,MAX_RANGE):\n",
        "  # Intervallo ricerca learning rate\n",
        "  lr = 10**random.uniform(lr_from, lr_to)\n",
        "  # lr = ... # FINER \n",
        "\n",
        "  with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "  with open(pipeline_fname, 'w') as f:\n",
        "          \n",
        "    # Set learning rate\n",
        "    s = re.sub('initial_learning_rate: [0-9.]+',\n",
        "              'initial_learning_rate: {}'.format(str(lr)), s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "  #!cat {pipeline_fname}\n",
        "\n",
        "  print('********** lr = '+str(lr)+' **********')\n",
        "\n",
        "  !python /content/api/research/object_detection/model_main.py \\\n",
        "      --pipeline_config_path={pipeline_fname} \\\n",
        "      --model_dir={model_dir} \\\n",
        "      --num_train_steps=120 \\\n",
        "      --save_checkpoints_steps=200 \\\n",
        "      --log_step_count_steps=20 \\\n",
        "      --keep_checkpoint_max=0 \\\n",
        "      --eval_throttle_secs=30 \\\n",
        "      --eval_start_delay_secs=30\n",
        "\n",
        "  !rm -r {model_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HHMVhi77bNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learning rate\n",
        "lr = 0.006397486877114805 #0.00400000018999\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "  s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "        \n",
        "  # Set learning rate\n",
        "  s = re.sub('initial_learning_rate: [0-9.]+',\n",
        "             'initial_learning_rate: {}'.format(str(lr)), s)\n",
        "\n",
        "  f.write(s)\n",
        "\n",
        "!cat {pipeline_fname}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dd-qjEzZQEZ",
        "colab_type": "text"
      },
      "source": [
        "# Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSGJ82gaZNJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output model directory\n",
        "model_dir = '/content/fit_output'\n",
        "\n",
        "# !!! Clean previous fit !!!\n",
        "!rm -r {model_dir}\n",
        "\n",
        "!mkdir {model_dir}\n",
        "\n",
        "# 10'000 -> 500\n",
        "save_checkpoints_steps = int(num_steps/40)\n",
        "\n",
        "# 10'000 -> 500\n",
        "log_step_count_steps = int(num_steps/40)\n",
        "\n",
        "# Maximum number of checkpoints to keep in storage. The oldest one are removed\n",
        "# newest are kept. 0 or None disables this feature.\n",
        "keep_checkpoint_max = 5\n",
        "\n",
        "# Evaluate every N seconds\n",
        "eval_throttle_secs = 480\n",
        "\n",
        "# Start evaluating after N seconds\n",
        "eval_start_delay_secs = 120\n",
        "\n",
        "!python /content/api/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --save_checkpoints_steps={save_checkpoints_steps} \\\n",
        "    --log_step_count_steps={log_step_count_steps} \\\n",
        "    --keep_checkpoint_max={keep_checkpoint_max} \\\n",
        "    --eval_throttle_secs={eval_throttle_secs} \\\n",
        "    --eval_start_delay_secs={eval_start_delay_secs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7vGPkrzab_x",
        "colab_type": "text"
      },
      "source": [
        "# Deploy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C5yyh0Mae-1",
        "colab_type": "text"
      },
      "source": [
        "## Export TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX5BL4Cpabd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "!mkdir /content/tflite_output\n",
        "tflite_output_directory = '/content/tflite_output'\n",
        "\n",
        "#lst = os.listdir(model_dir)\n",
        "#lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "#steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "#last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model = 'model.ckpt-4500'\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "\n",
        "print(last_model_path)\n",
        "\n",
        "!python /content/api/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "                --pipeline_config_path={pipeline_fname} \\\n",
        "                --trained_checkpoint_prefix={last_model_path} \\\n",
        "                --output_directory={tflite_output_directory} \\\n",
        "                --add_postprocessing_op=true\n",
        "\n",
        "!tflite_convert --graph_def_file={tflite_output_directory}/tflite_graph.pb \\\n",
        "                --output_file={tflite_output_directory}/detect.tflite \\\n",
        "                --input_arrays=normalized_input_image_tensor \\\n",
        "                --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "                --input_shapes=1,300,300,3 \\\n",
        "                --inference_type=FLOAT \\\n",
        "                --mean_values=128 \\\n",
        "                --std_dev_values=127 \\\n",
        "                --change_concat_input_ranges=false \\\n",
        "                --allow_custom_ops"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}